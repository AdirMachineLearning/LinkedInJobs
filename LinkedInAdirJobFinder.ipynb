{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b965a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Link</th>\n",
       "      <th>Cleaned Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Algorithm Scientist</td>\n",
       "      <td>Nova Ltd.</td>\n",
       "      <td>Center District, Israel</td>\n",
       "      <td>https://il.linkedin.com/jobs/view/algorithm-sc...</td>\n",
       "      <td>algorithm scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Scientist</td>\n",
       "      <td>MKS Instruments</td>\n",
       "      <td>Jerusalem District, Israel</td>\n",
       "      <td>https://il.linkedin.com/jobs/view/senior-scien...</td>\n",
       "      <td>senior scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scientist – Oligonucleotide R&amp;D Chemist</td>\n",
       "      <td>1E Therapeutics</td>\n",
       "      <td>Jerusalem</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/scientist-%...</td>\n",
       "      <td>scientist – oligonucleotide r&amp;d chemist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Single-Cell Deep Learning Scientist</td>\n",
       "      <td>Immunai</td>\n",
       "      <td>Ramat Gan, Tel Aviv District, Israel</td>\n",
       "      <td>https://il.linkedin.com/jobs/view/single-cell-...</td>\n",
       "      <td>Deep learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Single-Cell Deep Learning Scientist</td>\n",
       "      <td>Immunai</td>\n",
       "      <td>Tel Aviv-Yafo, Tel Aviv District, Israel</td>\n",
       "      <td>https://il.linkedin.com/jobs/view/single-cell-...</td>\n",
       "      <td>Deep learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Title          Company  \\\n",
       "0                      Algorithm Scientist        Nova Ltd.   \n",
       "1                         Senior Scientist  MKS Instruments   \n",
       "2  Scientist – Oligonucleotide R&D Chemist  1E Therapeutics   \n",
       "3      Single-Cell Deep Learning Scientist          Immunai   \n",
       "4      Single-Cell Deep Learning Scientist          Immunai   \n",
       "\n",
       "                                   Location  \\\n",
       "0                   Center District, Israel   \n",
       "1                Jerusalem District, Israel   \n",
       "2                                 Jerusalem   \n",
       "3      Ramat Gan, Tel Aviv District, Israel   \n",
       "4  Tel Aviv-Yafo, Tel Aviv District, Israel   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://il.linkedin.com/jobs/view/algorithm-sc...   \n",
       "1  https://il.linkedin.com/jobs/view/senior-scien...   \n",
       "2  https://www.linkedin.com/jobs/view/scientist-%...   \n",
       "3  https://il.linkedin.com/jobs/view/single-cell-...   \n",
       "4  https://il.linkedin.com/jobs/view/single-cell-...   \n",
       "\n",
       "                             Cleaned Title  \n",
       "0                      algorithm scientist  \n",
       "1                         senior scientist  \n",
       "2  scientist – oligonucleotide r&d chemist  \n",
       "3                            Deep learning  \n",
       "4                            Deep learning  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "class LinkedInJobs():\n",
    "    \"\"\"\n",
    "    A class to scrape job listings from LinkedIn based on specified job titles and locations.\n",
    "    \n",
    "    Attributes:\n",
    "        job_list (list): A list to store job data dictionaries.\n",
    "        job_title (str): The job title to search for.\n",
    "        location (str): The geographic location for the job search.\n",
    "        num_jobs (int): The total number of jobs to fetch.\n",
    "        jobs_per_page (int): Number of jobs listings per page.\n",
    "        num_pages (int): Total number of pages to scrape, calculated from num_jobs.\n",
    "        dataframe_jobs (DataFrame): A pandas DataFrame to store job data.\n",
    "        headers (dict): HTTP headers used for making requests.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, job_title, location, num_jobs):\n",
    "        \"\"\"\n",
    "        Constructs all the necessary attributes for the LinkedInJobs object.\n",
    "        \n",
    "        Parameters:\n",
    "            job_title (str): The job title to search for.\n",
    "            location (str): The geographic location for the job search.\n",
    "            num_jobs (int): The total number of jobs to fetch.\n",
    "        \"\"\"\n",
    "        self.job_list = []\n",
    "        self.job_title = job_title\n",
    "        self.location = location\n",
    "        self.num_jobs = num_jobs\n",
    "        self.jobs_per_page = 25\n",
    "        self.num_pages = math.ceil(num_jobs / self.jobs_per_page)\n",
    "        self.dataframe_jobs = None\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "    def get_jobs(self):\n",
    "        \"\"\"\n",
    "        Fetches job listings from LinkedIn and stores them in a DataFrame.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame: A DataFrame containing job listings with titles, companies, and locations.\n",
    "        \"\"\"\n",
    "        for page in range(self.num_pages):\n",
    "            offset = page * self.jobs_per_page\n",
    "            response = requests.get(\n",
    "                f'https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords={self.job_title}&location={self.location}&start={offset}',\n",
    "                headers=self.headers)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            job_listings = soup.find_all('li')\n",
    "            for job in job_listings:\n",
    "                title = job.find('h3', {'class': 'base-search-card__title'}).get_text(strip=True) if job.find('h3', {'class': 'base-search-card__title'}) else None\n",
    "                company = job.find('h4', {'class': 'base-search-card__subtitle'}).get_text(strip=True) if job.find('h4', {'class': 'base-search-card__subtitle'}) else None\n",
    "                location = job.find('span', {'class': 'job-search-card__location'}).get_text(strip=True) if job.find('span', {'class': 'job-search-card__location'}) else None\n",
    "                link = job.find('a', {'class': 'base-card__full-link'})['href'] if job.find('a', {'class': 'base-card__full-link'}) else None\n",
    "                self.job_list.append({'Title': title, 'Company': company, 'Location': location, 'Link': link})\n",
    "        self.dataframe_jobs = pd.DataFrame(self.job_list)\n",
    "        return self.dataframe_jobs\n",
    "\n",
    "    def clean_names(self):\n",
    "        \"\"\"\n",
    "        Cleans job titles in the DataFrame to standardize them based on predefined keywords.\n",
    "        \n",
    "        !!!!Remember to change the jobs names claening based on your needs!!!!\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame: The updated DataFrame with an additional column 'Cleaned Title' containing standardized job titles.\n",
    "        \"\"\"\n",
    "        standard_titles = {\n",
    "            'Data scientist': r'\\bdata scientist\\b',\n",
    "            'Data science': r'\\bdata science\\b',\n",
    "            'Data engineer': r'\\bdata engineer\\b',\n",
    "            'Deep learning': r'\\bdeep learning\\b',\n",
    "            'Machine learning engineer': r'\\bmachine learning engineer\\b',\n",
    "            'Machine learning': r'\\bmachine learning\\b',\n",
    "            'Data analyst': r'\\bdata analyst\\b',\n",
    "            'Software Developer': r'\\bsoftware developer\\b',\n",
    "            'Software Engineer': r'\\bsoftware engineer\\b',\n",
    "            'ML Ops': r'\\bml ops\\b',\n",
    "            'AI': r'\\bai\\b',\n",
    "            'Data architect': r'\\bdata architect\\b',\n",
    "            'AI engineer': r'\\bai engineer\\b',\n",
    "            'NLP': r'\\bnlp\\b',\n",
    "        }\n",
    "\n",
    "        def clean_title(title):\n",
    "            title = title.lower() \n",
    "            for standard, pattern in standard_titles.items():\n",
    "                if re.search(pattern, title):\n",
    "                    return standard  \n",
    "            return title  \n",
    "\n",
    "        self.dataframe_jobs['Cleaned Title'] = self.dataframe_jobs['Title'].apply(clean_title)\n",
    "        return self.dataframe_jobs\n",
    "\n",
    "\n",
    "# Define the job title, location, and number of jobs to scrape\n",
    "job_title = 'data scientist'\n",
    "location = 'Israel'\n",
    "num_jobs = 10\n",
    "\n",
    "job_scraper = LinkedInJobs(job_title, location, num_jobs)\n",
    "df_class = job_scraper.get_jobs()\n",
    "df_cleaned = job_scraper.clean_names()\n",
    "pd.options.display.max_rows = None\n",
    "display(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc2b585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
